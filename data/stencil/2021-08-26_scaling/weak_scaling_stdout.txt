Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.032 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.6908156014978886
Elapsed (total): 1.7898119445890188
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.6484505906701088
Elapsed (total): 1.8581845965236425
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.2757445629686117
Elapsed (total): 0.9331912491470575
[Partition 0][Node 0] End of program
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5833749771118164
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2545769214630127
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.015 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.3176008928567171
Elapsed (total): 1.0113585460931063
[Partition 0][Node 0] End of program
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5898840427398682
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.034 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.8469856549054384
Elapsed (total): 2.5305922757834196
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.25812721252441406
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.030 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5981620792299509
Elapsed (total): 1.664493527263403
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.6546800136566162
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.030 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.667021457105875
Elapsed (total): 1.7777878046035767
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.29221010208129883
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5715069770812988
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.005 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.26513264887034893
Elapsed (total): 0.7737712990492582
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5837349891662598
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.030 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.6288040559738874
Elapsed (total): 1.584716111421585
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.25733304023742676
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5498771667480469
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.27414170652627945
Elapsed (total): 0.9265595264732838
[Partition 0][Node 0] End of program
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4604790210723877
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5005167908966541
Elapsed (total): 1.479724608361721
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.006 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.26420833542943
Elapsed (total): 0.7713797129690647
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5019465163350105
Elapsed (total): 1.588809136301279
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.48040921241045
Elapsed (total): 1.4202458448708057
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.6785131376236677
Elapsed (total): 2.392672909423709
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.44141697883605957
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.015 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.3149989750236273
Elapsed (total): 1.0152231100946665
[Partition 0][Node 0] End of program
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.45537614822387695
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2873351573944092
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2538900375366211
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5455131530761719
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.45942673459649086
Elapsed (total): 1.299465335905552
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.49597692489624023
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.47061705589294434
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4733918234705925
Elapsed (total): 1.5858447290956974
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4756158161908388
Elapsed (total): 1.3917312920093536
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2586660385131836
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.25224804878234863
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.2747348006814718
Elapsed (total): 0.9258418958634138
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.3190133050084114
Elapsed (total): 1.0171737894415855
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.28730010986328125
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.039 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.6246489696204662
Elapsed (total): 2.3103144876658916
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.446491003036499
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5615770816802979
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.006 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.2638092190027237
Elapsed (total): 0.7716283947229385
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4755280241370201
Elapsed (total): 1.4654686748981476
[Partition 0][Node 0] End of program
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4578549861907959
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.25719499588012695
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5223078727722168
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4726950768381357
Elapsed (total): 1.4484359081834555
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4433891773223877
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.486520791426301
Elapsed (total): 1.5891208406537771
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.2750450111925602
Elapsed (total): 0.9328430201858282
[Partition 0][Node 0] End of program
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.47495603561401367
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4563479423522949
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4632583800703287
Elapsed (total): 1.4343943651765585
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2875208854675293
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.25279998779296875
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.581464970484376
Elapsed (total): 2.314038949087262
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4813849925994873
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4580571074038744
Elapsed (total): 1.2847659438848495
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.31668468192219734
Elapsed (total): 1.0089859198778868
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.005 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.26448702439665794
Elapsed (total): 0.7714904062449932
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.2714682165533304
Elapsed (total): 0.9087403826415539
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2836730480194092
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  6144 3072
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.31452428363263607
Elapsed (total): 1.0106228590011597
[Partition 0][Node 0] End of program
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2545750141143799
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.006 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  3072 1536
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.2635464295744896
Elapsed (total): 0.7699038349092007
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.032 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5910890325903893
Elapsed (total): 1.7413606084883213
[Partition 0][Node 0] End of program
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.6255209445953369
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.033 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.6978809796273708
Elapsed (total): 2.537838865071535
[Partition 0][Node 0] End of program
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.46999382972717285
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.45991062745451927
Elapsed (total): 1.2972969077527523
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  3072 3072
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.2583339214324951
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.033 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  12288 12288
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.7090002112090588
Elapsed (total): 1.7311015892773867
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.6522700786590576
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  12288 6144
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4709294904023409
Elapsed (total): 1.3398450519889593
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  6144 6144
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4521160125732422
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 12288
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.4993870258331299
