X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.0229029655456543
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 7.435441017150879
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.48607897758483887
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.035 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 1.909170901402831
Elapsed (total): 3.070272032171488
[Partition 0][Node 0] End of program
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 32.80455303192139
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 3.751207360997796
Elapsed (total): 4.983011974021792
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 7.445503242313862
Elapsed (total): 8.96876160427928
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.033 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5328833740204573
Elapsed (total): 1.8247707169502974
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 9.397048950195312
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.009 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 15.995437802746892
Elapsed (total): 18.23185208812356
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 15.987711906433105
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.9706522021442652
Elapsed (total): 2.091461654752493
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 9.45977715216577
Elapsed (total): 11.04666043072939
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.005 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 32.66933442465961
Elapsed (total): 36.449473943561316
[Partition 0][Node 0] End of program
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.9032540321350098
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 3.742331027984619
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 3.770722473040223
Elapsed (total): 4.9825727827847
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 9.416968822479248
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.9616400469094515
Elapsed (total): 2.1113726906478405
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 7.460569282993674
Elapsed (total): 8.98753178678453
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.4922708608210087
Elapsed (total): 1.9297445807605982
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 15.984934091567993
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 9.462328871712089
Elapsed (total): 11.057242201641202
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 7.4723029136657715
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 16.002298587933183
Elapsed (total): 18.240123640745878
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 1.8897428344935179
Elapsed (total): 3.149046152830124
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.006 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 32.86120651476085
Elapsed (total): 36.63084330782294
[Partition 0][Node 0] End of program
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.9727270603179932
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 32.85241985321045
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.9619748592376709
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5347809791564941
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 3.7554221153259277
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 15.993997488170862
Elapsed (total): 18.23227937705815
[Partition 0][Node 0] End of program
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 15.988510131835938
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 1.3099007532000542
Elapsed (total): 2.4853863548487425
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.005 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 34.13392532616854
Elapsed (total): 37.911594931036234
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 7.4572460651397705
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.945897102355957
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 9.41654109954834
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5497108083218336
Elapsed (total): 2.050960870459676
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 3.7698112931102514
Elapsed (total): 4.987282980233431
[Partition 0][Node 0] End of program
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.0318529605865479
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 3.7432591915130615
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 1.9208114929497242
Elapsed (total): 3.1433032155036926
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 9.441899504512548
Elapsed (total): 11.03200770355761
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 7.464475333690643
Elapsed (total): 8.989152951166034
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5249969959259033
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 32.78753209114075
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 15.983314990997314
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 32.47319483757019
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.005 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 32.77330691926181
Elapsed (total): 36.553006855770946
[Partition 0][Node 0] End of program
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 7.437412977218628
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 3.7370669841766357
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.9215271472930908
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 9.442624051123857
Elapsed (total): 11.041981566697359
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 7.464648678898811
Elapsed (total): 8.987422777339816
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 9.465505838394165
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.010707139968872
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 1.9202021174132824
Elapsed (total): 3.0633515045046806
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.45903309993445873
Elapsed (total): 2.0701604913920164
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.9324701651930809
Elapsed (total): 2.094040909782052
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.5452530384063721
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 15.988114088773727
Elapsed (total): 18.22494090721011
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 3.764998733997345
Elapsed (total): 4.979411631822586
[Partition 0][Node 0] End of program
X, y: 24 32
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.6104440689086914
X, y: 3 4
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 15.988709926605225
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 48 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  48
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 7.459163540974259
Elapsed (total): 8.985696587711573
[Partition 0][Node 0] End of program
X, y: 8 12
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 3.768634080886841
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 6 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.006 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  6
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 32.87142622470856
Elapsed (total): 36.651794623583555
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 12 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.008 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  12
Number of processors        =  12
Grid shape (x,y)            =  3 4
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 16.023700270801783
Elapsed (total): 18.25965739414096
[Partition 0][Node 0] End of program
X, y: 16 24
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 0.940960168838501
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 192 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 4 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  192
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 1.8931205682456493
Elapsed (total): 3.1455737110227346
[Partition 0][Node 0] End of program
X, y: 12 16
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  192
Grid shape (x,y)            =  12 16
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 1.8938651084899902
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 768 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 16 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  768
Number of processors        =  768
Grid shape (x,y)            =  24 32
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.5202723555266857
Elapsed (total): 1.8390595763921738
[Partition 0][Node 0] End of program
X, y: 4 6
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 9.424422979354858
X, y: 6 8
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  48
Grid shape (x,y)            =  6 8
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 7.452188014984131
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 384 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 8 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.031 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  384
Number of processors        =  384
Grid shape (x,y)            =  16 24
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 0.9525162260979414
Elapsed (total): 2.1095926593989134
[Partition 0][Node 0] End of program
X, y: 2 3
Python MPI/Numpy  Stencil execution on 2D grid
Number of processors        =  6
Grid shape (x,y)            =  2 3
Problem Domain (x,y)        =  24576 24576
Number of warmup iterations =  10
Number of iterations        =  100
Elapsed: 33.022794008255005
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 24 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 1 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.014 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  24
Number of processors        =  24
Grid shape (x,y)            =  4 6
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 9.434139551594853
Elapsed (total): 11.030205523595214
[Partition 0][Node 0] End of program
Charm++> Running on MPI version: 3.1
Charm++> level of thread support used: -1 (desired: 0)
Charm++> Running in non-SMP mode: 96 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-29-gdae86b4e1
Isomalloc> Disabling global synchronization of address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm4py> Running Charm4py version 1.0 on Python 3.9.6 (CPython). Using 'cython' interface to access Charm++
Charm++> Running on 2 hosts (2 sockets x 24 cores x 2 PUs = 96-way SMP)
Charm++> cpu topology info is gathered in 0.029 seconds.
Python Charm/Numpy  Stencil execution on 2D grid
Number of chares            =  96
Number of processors        =  96
Grid shape (x,y)            =  8 12
Problem Domain (x,y)        =  24576 24576
Number of iterations        =  100
Number of warmup iterations =  10
Elapsed: 3.7685889303684235
Elapsed (total): 4.988106492906809
[Partition 0][Node 0] End of program
